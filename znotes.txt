
I've listed a few things to discuss below (in no particular order), but we
should not restrict ourselves to only these items.  Anything is on the table.

- The name "warp" was fun (warp_Core, warp_Drive), but may not be the best
  choice.  I am completely open to changing it.

- The prefix choices of 'warp_' for user routines and '_warp_' for internal
  routines was an experiment.  I'm not sure if I actually like it.

- I put almost everything in one big file just out of laziness.  The code
  definitely needs to be organized in separate files with comments, etc.

- I essentially wrote the code as if the 'core' was a global collection of data
  that any routine can modify, but I pass it around in every call.  I found this
  to be convenient, but not particularly elegant.

- The most difficult aspect of writing this code revolved around the decision to
  only store the solution at C-points.  This may give us the potential to save a
  lot of memory (the coarsening factor does not appear to affect convergence).
  I am happy about the FRestrict(), FInterp(), ... design, but I am not
  completely happy about the warp_U* routine interface, because it has some
  inconsistencies.  The idea to hide the complications of C-point storage behind
  an interface is good, but feedback on what I actually did would be great.

- Because of the C-point storage, and to minimize cost, I compute the residual
  norm in the FRestrict() routine when going from level 0 to level 1.  I do not
  check the norm until the V-cycle is complete, so extra work is done.  If we
  stop immediately, extra work would need to be done anyway in the FWrite()
  routine to recompute the F-point values (since they are not stored).  I am not
  sure what we should do here in practice.

- I also made the decision to use an absolute residual norm criteria.  This is
  the same approach that PETSc uses.  If a relative criteria is desired, users
  will need to modify the 'tol' parameter by multiplying it by an initial
  residual norm (or something).  I think this is the best approach, but I'd like
  to discuss this. 
  --> One alternative would be to stop based on ||r_1|| / ||r_k|| where r is
      the residual evaluated at C-points.  

- Currently, the parallel distribution assumes equal computational cost at each
  temporal point.  This may not be the case for users doing refinement in both
  space and time, so we will need to develop a mechanism for determining and
  using a set of weights to define a load-balanced distribution.

- I have hooks in the code for users to do spatial refinement.  This has not
  been tested.

- To get FMG working, we need to write the FRefine() routine.  The first step is
  to make the assumption that data redistribution is not needed.  We can add
  load balancing later.

- I'm not exactly sure what we should do with the solution that we compute.
  Currently, I have the FWrite() routine, which was originally designed with the
  idea of writing the solution to file.  However, it could in theory do other
  things, since it sits on top of a user-written function.  Also, since we are
  computing a hierarchy of solutions, there may be an opportunity to do
  something "different" from traditional practice.  Ideas?

- Feedback on the user-provided "refine" approach I am using for building the
  FMG hierarchy and finest mesh would be great.

==========

8/15/2013 Meeting

- Think about the need for g_i.  In a purely nonlinear setting, may not need.

- Consider putting functions in the app structure, so app is not entirely opaque
  as it it now.


